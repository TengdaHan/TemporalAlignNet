# Temporal Alignment Network for long-term Video 

Tengda Han, Weidi Xie, Andrew Zisserman. CVPR2022 Oral.

[[project page]](https://www.robots.ox.ac.uk/~vgg/research/tan/)
[[PDF]](https://www.robots.ox.ac.uk/~vgg/publications/2022/Han22a/han22a.pdf)
[[Arxiv]](https://arxiv.org/abs/2204.02968)
[[Video]](https://youtu.be/77dcM9CyHCY)

<img src="TAN_teaser.png" width="800">

### Datasets
* [**HTM-Align**](htm_align/): A manually annotated 80-video subset for alignment evaluation.
* [**HTM-AA**](htm_aa/): A large-scale video-text paired dataset automatically aligned using our TAN without using any manual annotations.

### Tool
* [**Sentencify-text**](sentencify_text/): A pipeline to pre-process ASR text segments and get full sentences.

### Notes
* We aim to release other code/model before the conference session (June 21). Thanks for your interest!

### Reference
```
@InProceedings{han2022align,
  title={Temporal Alignment Network for long-term Video},  
  author={Tengda Han and Weidi Xie and Andrew Zisserman},  
  booktitle={CVPR},  
  year={2022}}
```




